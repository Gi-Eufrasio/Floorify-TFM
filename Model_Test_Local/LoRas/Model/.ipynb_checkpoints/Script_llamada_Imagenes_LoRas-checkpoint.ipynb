{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d725f368-cca5-4038-b25e-37f124e93f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9671261d-d485-41d0-91dc-3b3afc1ea3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = load_dataset(\"umesh16071973/New_Floorplan_demo_dataset\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "239b6533-b86f-464d-be6d-50f32adfc606",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1b567da9-04ec-42de-8999-05599c44fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./my_concept/prompt1\"\n",
    "x = teste[\"image\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "657777fd-8071-4c43-814f-81aa09a060af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.extract_Imagenes(path, image, contador)>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b24bf0f2-64b1-4054-a4c6-0da9c66ae753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def delete_images_in_directory(directory):\n",
    "    # Lista de extensões de arquivos de imagem comuns\n",
    "    image_extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.gif\", \"*.bmp\", \"*.tiff\", \"*.webp\"]\n",
    "    \n",
    "    # Percorre cada extensão de imagem e remove os arquivos correspondentes\n",
    "    for extension in image_extensions:\n",
    "        # Usa glob para encontrar todos os arquivos com a extensão especificada\n",
    "        files = glob.glob(os.path.join(directory, extension))\n",
    "        for file in files:\n",
    "            try:\n",
    "                os.remove(file)\n",
    "                #print(f\"Deleted {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {file}. Reason: {e}\")\n",
    "\n",
    "# Diretório de exemplo (substitua pelo diretório que você deseja limpar)\n",
    "directory = [\"./my_concept/prompt1\", \"./my_concept/prompt2\", \"./my_concept/prompt3\", \"./my_concept/prompt4\", \"./my_concept/prompt5\"]\n",
    "\n",
    "for x in lista:\n",
    "    # Chama a função para apagar as imagens\n",
    "    delete_images_in_directory(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d935b57-df40-4545-99ea-1db4f3fa50ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4c464c06-1e1b-4961-a0c4-01e1b6304e7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 63)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:63\u001b[0;36m\u001b[0m\n\u001b[0;31m    time.sleep(1)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def extract_elements(text):\n",
    "    # Define padrões de expressão regular para os diferentes elementos\n",
    "    patterns = {\n",
    "        'rooms': r'(\\d+)\\s+room[s]?',\n",
    "        'bathrooms': r'(\\d+)\\s+bathroom[s]?',\n",
    "        'kitchens': r'(\\d+)\\s+kitchen[s]?',\n",
    "        'basement': r'(\\d+)\\s+basement[s]?',\n",
    "        'bedrooms': r'(\\d+)\\s+bedroom[s]?',\n",
    "        'dining rooms': r'(\\d+)\\s+dining room[s]?',\n",
    "    }\n",
    "\n",
    "    elements = {}\n",
    "    # Extrai as informações usando as expressões regulares definidas\n",
    "    for element, pattern in patterns.items():\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            elements[element] = int(match.group(1))\n",
    "        else:\n",
    "            elements[element] = 0  # Caso o elemento não seja encontrado, definir como 0\n",
    "\n",
    "    return elements\n",
    "\n",
    "\n",
    "def delete_ipynb_checkpoints(directory):\n",
    "    # Percorre o diretório raiz e todos os subdiretórios\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for dir_name in dirs:\n",
    "            if dir_name == '.ipynb_checkpoints':\n",
    "                # Caminho completo do diretório .ipynb_checkpoints\n",
    "                dir_path = os.path.join(root, dir_name)\n",
    "                try:\n",
    "                    shutil.rmtree(dir_path)\n",
    "                    print(f\"Deleted directory: {dir_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to delete directory {dir_path}. Reason: {e}\")\n",
    "                    \n",
    "\n",
    "def extract_Imagenes(path, image, contador):\n",
    "    \n",
    "    output_path = os.path.join(path, f'image_{str(contador)}.png')\n",
    "    time.sleep(1)\n",
    "    image.save(output_path)\n",
    "        \n",
    "    # Diretório alvo\n",
    "    directory = path\n",
    "    files = os.listdir(directory)\n",
    "    time.sleep(1)\n",
    "    \"\"\"\n",
    "    # Diretório alvo\n",
    "    directory = './my_concept/prompt1/'\n",
    "    \n",
    "    # Listar todos os arquivos no diretório\n",
    "    files = os.listdir(directory)\n",
    "    for file in files:\n",
    "        image = Image.open(f\"./my_concept/{file}\")\n",
    "        image = image.convert(\"L\")\n",
    "        image.save(os.path.join(directory, file))\"\"\"\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        if file == \".ipynb_checkpoints\":\n",
    "             delete_ipynb_checkpoints(path)\n",
    "            time.sleep(1)    \n",
    "        else:\n",
    "            image = Image.open(f\"{path}{file}\")\n",
    "            resized_I = (512,512)\n",
    "            resized_image = image.resize((512,512), Image.ANTIALIAS)\n",
    "            resized_image.save(os.path.join(directory, file))\n",
    "    \n",
    "contador = int(0)\n",
    "\n",
    "for linhas in teste:\n",
    "\n",
    "    contador += 1\n",
    "    \n",
    "    # Texto de exemplo\n",
    "    text = str(linhas[\"text\"])\n",
    "    \n",
    "    # Extrair elementos do texto\n",
    "    extracted_elements = extract_elements(text)\n",
    "    \n",
    "    if str(extracted_elements[\"rooms\"]) == str(1):\n",
    "        output_dir = \"./my_concept/prompt1/\"\n",
    "        extract_Imagenes(output_dir, linhas[\"image\"], contador)\n",
    "        \n",
    "    if str(extracted_elements[\"rooms\"]) == str(2):\n",
    "        output_dir = \"./my_concept/prompt2/\"\n",
    "        extract_Imagenes(output_dir, linhas[\"image\"], contador)\n",
    "        \n",
    "    if str(extracted_elements[\"rooms\"]) == str(3):\n",
    "        output_dir = \"./my_concept/prompt3/\"\n",
    "        extract_Imagenes(output_dir, linhas[\"image\"], contador)\n",
    "        \n",
    "    if str(extracted_elements[\"rooms\"]) == str(4):\n",
    "        output_dir = \"./my_concept/prompt4/\"\n",
    "        extract_Imagenes(output_dir, linhas[\"image\"], contador)\n",
    "        \n",
    "    if str(extracted_elements[\"rooms\"]) == str(5):\n",
    "        output_dir = \"./my_concept/prompt5/\"\n",
    "        extract_Imagenes(output_dir, linhas[\"image\"], contador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7bd18caa-6883-4655-a47b-8964790dacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for linhas in teste:\n",
    "    \n",
    "    # Texto de exemplo\n",
    "    text = str(linhas[\"text\"])\n",
    "    \n",
    "    # Extrair elementos do texto\n",
    "    extracted_elements = extract_elements(text)\n",
    "    \n",
    "    if extracted_elements[\"rooms\"] == str(5):\n",
    "        output_dir = \"./my_concept/prompt3/\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8bce2-3088-4453-bd22-412f6bb0a893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c02c0c3a-6928-4a2b-9c3b-35dd72d7363f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# Caminho para o diretório onde os pesos LoRa estão localizados\n",
    "model_path = \"path-to-save-model\"\n",
    "lora_weights_path = os.path.join(model_path, \"pytorch_lora_weights.safetensors\")\n",
    "\n",
    "# Verificar se o arquivo de pesos LoRa existe\n",
    "if not os.path.exists(lora_weights_path):\n",
    "    raise ValueError(f\"O arquivo necessário '{lora_weights_path}' não existe no diretório '{model_path}'.\")\n",
    "\n",
    "# Carregar o pipeline de difusão estável usando o modelo base\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "# Carregar os pesos LoRa\n",
    "lora_weights = load_file(lora_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a9f4b5e3-4c01-4105-bbbf-ee678f3be09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 23.49it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.44it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.43it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.42it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 23.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagens geradas e salvas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Aplicar os pesos LoRa ao modelo base\n",
    "for name, param in pipeline.unet.named_parameters():\n",
    "    if name in lora_weights:\n",
    "        param.data += lora_weights[name].data\n",
    "\n",
    "# Definir o scheduler se necessário\n",
    "pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)\n",
    "\n",
    "# Definir o prompt para gerar imagens\n",
    "prompt = \"floor plan 2D without colors, just drawn\"\n",
    "\n",
    "# Gerar imagens\n",
    "num_images = 5  # Número de imagens a serem geradas\n",
    "for i in range(num_images):\n",
    "    with torch.cuda.amp.autocast():  # Use mixed precision\n",
    "        image = pipeline(prompt).images[0]\n",
    "        image.save(f\"generated_image_{i}.png\")\n",
    "        torch.cuda.empty_cache()  # Liberar memória entre as gerações\n",
    "\n",
    "print(\"Imagens geradas e salvas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4572180c-2fae-412e-919f-406ed3b7b95f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
